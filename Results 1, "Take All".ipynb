{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results 1\n",
    "This experiment implements the simpliest way to use a feature extractor.   \n",
    "It just compares features from the catalogue to the features from query models.   \n",
    "It gives a **30%** 10-accuracy result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "to_ignore = [53,89,110,120,127,131,144,167,159,190]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "### Catalogue Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 items in the catalogue\n"
     ]
    }
   ],
   "source": [
    "cat_dir = 'db/robes/cat/'\n",
    "list_cat = [cat_dir+f for f in os.listdir(cat_dir) if re.search('jpg|JPG', f)]\n",
    "list_cat = list(filter(lambda x: \"_0\" in x, list_cat))\n",
    "list_cat.sort(key=lambda x: int(x.split(\"/\")[-1].split(\"_\")[0]))\n",
    "print(str(len(list_cat))+\" items in the catalogue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 queries to perform\n"
     ]
    }
   ],
   "source": [
    "query_dir = 'db/robes/mod/'\n",
    "list_query = [query_dir+f for f in os.listdir(query_dir) if re.search('jpg|JPG', f)]\n",
    "list_query.sort(key=lambda x: int(x.split(\"/\")[-1].split(\".\")[0]))\n",
    "print(str(len(list_cat))+\" queries to perform\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = 'models'\n",
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "create_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Returns the feature vectors corresponding to a list of image\n",
    "def extract_features(list_images,p=False):\n",
    "    nb_features = 2048\n",
    "    features = np.zeros((len(list_images),nb_features))\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "    for ind, image in enumerate(list_images):\n",
    "        if ind in to_ignore:\n",
    "            if p:\n",
    "                print('Ignore item %d'%(ind))\n",
    "                print('Feature vector:', features[ind,:])\n",
    "            continue\n",
    "        if (ind%1 == 0) and p:\n",
    "            print('Processing %s...' % (image))\n",
    "        if not gfile.Exists(image):\n",
    "            tf.logging.fatal('File does not exist %s', image)\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "        predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': image_data})\n",
    "        features[ind,:] = np.squeeze(predictions)\n",
    "        if p:\n",
    "            print('Feature vector:', features[ind,:])\n",
    "        labels.append(io.BytesIO(image_data))\n",
    "    print(\"Done\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "cat_features = extract_features(list_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "query_features = extract_features(list_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 210)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Safety check\n",
    "len(cat_features),len(query_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Results\n",
    "For each queries, the best matching items in the catalogue, according to cosine similarity, are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cosine Similarity\n",
    "def sim(vecA,vecB):\n",
    "    return vecA.dot(vecB)\n",
    "#Perform the best matching retrieval\n",
    "#Accuracy: what it means to match, by default it is to be in the top 10 closest\n",
    "#p: print debug\n",
    "def query(i_query,accuracy=10,p=False):\n",
    "    sim_vec = []\n",
    "    for i in range(len(cat_features)):\n",
    "        sim_vec.append(sim(query_features[i_query],cat_features[i]))\n",
    "    sim_vec = np.array(sim_vec)\n",
    "    arg_s = sim_vec.argsort()[:-accuracy:-1]\n",
    "    if p:\n",
    "        print(i_query,arg_s,[sim_vec[i] for i in arg_s], sim_vec[i_query])\n",
    "    return i_query in arg_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Normalization before querying\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        cat_features[i] /= np.linalg.norm(cat_features[i])\n",
    "        query_features[i] /= np.linalg.norm(query_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting result while getting rid of ignored val\n",
    "matching_frac = 0\n",
    "ignored = 0\n",
    "for i in range(len(cat_features)):\n",
    "    if not i in to_ignore:\n",
    "        matching_frac += query(i)\n",
    "    else:\n",
    "        ignored += 1\n",
    "matching_frac /= (len(cat_features)-ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This method gives a 30.0 10-accuracy success\n"
     ]
    }
   ],
   "source": [
    "print(\"This method gives a \"+str(matching_frac*100)+\" 10-accuracy success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is **bad** because it doesn't look where it should to identify the dress correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
